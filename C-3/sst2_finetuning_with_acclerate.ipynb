{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XokZpVVZg4Kd",
        "outputId": "58afd45c-b73b-43c1-a880-8a0fc3e7eb0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.10.0+cu128)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.24.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]) (5.29.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers[sentencepiece]) (0.24.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers[sentencepiece]) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers[sentencepiece]) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers[sentencepiece]) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers[sentencepiece]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers[sentencepiece]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers[sentencepiece]) (0.1.2)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate accelerate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data, checkpoint and tokenizer\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"sst2\")\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508,
          "referenced_widgets": [
            "42dcfc97daf3457b8fc0b547ca95bc21",
            "babf90cbb83543a6acf956735ae17e69",
            "a8413a0333f8409691d3753f51482eee",
            "3924493ef2404a10ab7f68d77bf7138f",
            "d76653c6e41141ccb9efd71898c418ae",
            "c4846277f8b241beafce317933f4684f",
            "51ea1216dc2c40e1ad055ea402fcc703",
            "fa1a90f38d3f4a62b5511892028fc236",
            "29eed3c2702748ab9e671e83ecd9e364",
            "45a0a061573c4c5b82698e48dca74d6c",
            "99cbe50599ae4918b4b2879bf0a9916f",
            "dafed459c2a642169d25d0861de11158",
            "2b43ba94350c4403bbc31d5d8dc63a14",
            "fe72b7bfa0d843ed80958f2c1c14e250",
            "2ff6e43083d943398b9a00a10f260060",
            "9f3e9f5ccfab4e76b153aca8a544ff2f",
            "33f64a6720764e109e0d77a794b312f9",
            "0901d85310054a9691e464388252d9fa",
            "53daf34d7f974534b94886d99c6276bd",
            "1266033ce7924aaf99d46c02f646ac7d",
            "ba850968af234aaead2b10ba537c7787",
            "1d89bfc0959f4f5687dd757df9cb96a3",
            "eab9aa232e45472390f17ad11afbd60f",
            "9b869b75d8c345c8899efa3807253826",
            "b7e0d5cea7714f57b192dd37be672bb5",
            "4932340f60fc41c3bdfab8f70241a6e2",
            "007e22bb681d4678979f9196e92af840",
            "76d0299938b946f2bc59751d782a99cb",
            "c28b095ee4d24e6c8e1298977cceadce",
            "52bc1f35a8d244d2aca109d45f1b99f4",
            "f4000ec63bc1424f9087f8404c11f3d4",
            "711a713dd0ad4f11836468dc3fe2672c",
            "0d96c82519264761816697efbfa4c4d6",
            "1f631f53ef5e41288537840ccdddd1c1",
            "3b98931dd0da4c11a3dd895663be9e01",
            "6044ca465f1c43f78c4fc4e0dfed5e1d",
            "ab3790e2519241f39e04423950bc7dd9",
            "b4e7092c186e42ec9b6cc82fcef6ea2e",
            "01a5f2e4327f403dbf02691bae395764",
            "492f1951204c478c8d0c1bcbe77d00d1",
            "757f8869fb614758b015b00def357c52",
            "e3ceeeb8d09a41ecb8063d5ab1a3bb72",
            "63e46f239be2497d9e9a54b3b4a64e0c",
            "7efce9f0cc54437a90fd6ba5410882ee",
            "f18872faad2a47068ff2934133cd9b4b",
            "26b2643d98e54ce38baf682322d4dc86",
            "c816448ee9bb4c8b897c929594e78553",
            "a67fbd35e6ff4b89b01d74a2b77252ed",
            "dc2f798c1626409c92ad4c5c15b00813",
            "9ff108f1a6fa4d139f6b26a3c18acb8a",
            "265ad7074da74f21be3cadfe748354e5",
            "9a81494ac6c04217b25bf9fe2b1dff9c",
            "9f60052c80a144a781591d4ff95af042",
            "5829099b0f2a49439eb858643776ca53",
            "a3a4538c9dcf4f0f9fea6ff90a62e2b5",
            "22265b2cb74f4a549052d652b0313ca8",
            "b2a3bdb9fb364acf8fbc48976ac71046",
            "8ab6753141ae445b9f466cd00195484e",
            "8a9417b209534b0fada935266c3d2c9a",
            "22ead03985fb44ecaed964c275f2cfb2",
            "f38a82d9d4b2461c9131925ea80693c1",
            "d99b101dcdc14ea9ba0b7e84c62fa31d",
            "964c78a8cf8e4dc7b1ee43e5b6169241",
            "aafff8bb40c64ed3841ee566ef9cbe6f",
            "e093350965694aee97451f486c3c1acb",
            "428506d681a047b9a3fd977227a7e573",
            "56c740df7c0d4b90a94e59e8f04040ef",
            "720526fd3cad4270a92ed783e07d47f5",
            "80cf61f7b4c84aa0870be09094aa52ec",
            "1dc394c774b848d7ac83772e26055107",
            "095743bd02af47beabfb534df660430b",
            "340fb3d0e0d84c34ac1c49ad12205150",
            "de33bc7f3ec843379f800e6bcd6f3047",
            "cae582c9908343cfbb5ea202ee173ed1",
            "c05c7e4d034e4a0495b9c914309d5460",
            "a97d39288bdd461d918708f788f35231",
            "e53a5efef8e444c9a71ea903b8e51331",
            "d8c30e8ae6c741f389be8882d6c0938f",
            "ca166a8f16134203afa3b9ed2fd68540",
            "3a0baf928edd405d8466c7e49cb5ca93",
            "d8101066a3ca4fffa048c71c0386bec8",
            "42ed17582f9a4ab2acbc4901f896ed6b",
            "a7e34726f5974cf2ad0b719082d90c18",
            "45915f5e305b44bab0db17645580c61c",
            "586a0f82c1b34f22b2116c9fa31da8ee",
            "09bbd33724ec47e19ac172d093ab391b",
            "698edabdd60841c6942ce9635f961a13",
            "830f1611ad7441478d4bc612f2c8cccc",
            "7a2f714c35514fd7b0b03facfe2cae5e",
            "08f96cfeeca0460ca829c8fef683ce9e",
            "a67d4ab5e16f4348a8ba9533a2d58c5d",
            "546c5d9e1c9d4002909d155b09c4f1f8",
            "b709bc897c3643a99ed32edbde3c5b4c",
            "155cb2022a374308bb8a7c5a5aea2d07",
            "410dd76a29554356b22d5cc472799f81",
            "a3df464f76a74b5a8add78dfa8c9b06e",
            "4141e8d023514adb9967fcaeaa2f4515",
            "6a143460a39b4bf790c0aa0e671fb494",
            "52fea3c99a844c5088b50aea064eb883",
            "eff7564e7a494823966b1d7e2b2f718a",
            "b523b3a677624942b27df96dbb05c104",
            "fe3047ebb66e4fcea506d912178a1070",
            "c969e26dd8ce4fa1bbcb67741e9a1ea2",
            "030b95a6c82343cca11c24aa8193da8f",
            "581a85c128f943718380f2532b0fc1e8",
            "f9e5ce8a14174139afdbd0481f155c7b",
            "b21e4b45c4174678ab134a28f85c367b",
            "cb7df5feabd54458acc495e613b6ae13",
            "0f55b855aca34eecabc065dbf40f6285",
            "3923ad0b8d8d4f02915bf4a4bc547bac",
            "deac68262d644396a1d29fca37326408",
            "d06b6171ee45479f8ae5ca7783f3d88e",
            "3f71c00453394cafb822f2ac7628f79b",
            "ea757c10f1bc42fc8fa54c208905156b",
            "b70c5760310e412d923e15177e7dbdc4",
            "c61a3666884342b6af702b1abcc43582",
            "e8bd5fb8cccc4cb0ae37e7093c674111",
            "6b7b704aff7245149999bb54bc52f264",
            "961330ad5ada4f6393c1945735577008",
            "685c87c5cefc45589dccb09805125b02",
            "460b305826774b21a8874161827f264a"
          ]
        },
        "collapsed": true,
        "id": "XziqRZ-4hQ0W",
        "outputId": "91f94f91-e364-418d-aa6d-ce2b8ce29efd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["README.md: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42dcfc97daf3457b8fc0b547ca95bc21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sst2/train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dafed459c2a642169d25d0861de11158"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sst2/validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eab9aa232e45472390f17ad11afbd60f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sst2/test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f631f53ef5e41288537840ccdddd1c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f18872faad2a47068ff2934133cd9b4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22265b2cb74f4a549052d652b0313ca8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c740df7c0d4b90a94e59e8f04040ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8c30e8ae6c741f389be8882d6c0938f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a2f714c35514fd7b0b03facfe2cae5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eff7564e7a494823966b1d7e2b2f718a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deac68262d644396a1d29fca37326408"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": ["raw_datasets"],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn_osPf6iB1j",
        "outputId": "0dfc6d4d-575f-4278-ce47-6d2eb51ac715"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the dataset\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence\"], truncation=True)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "0714840aa8ea43009f9a6f25cf2b65cc",
            "1f1666120589466eb915484326c66d48",
            "c11e832929dc491b9363bc88b020240e",
            "b2caf1290a844ebe8ddfde8ae58e70a7",
            "93cc74dbd4324030acb6c17bd5adc765",
            "5ab9fdceef744884a0b5e0b3e258193a",
            "61ec497b6faf4908b333689168421237",
            "953165f31e7145a7874c81a1a2fcaf43",
            "09e3deb9c3224c60b454b1944ba1b302",
            "1ca8ea7094744ca38dc9243a0cac6134",
            "59f8320b79a7495d9ba38524c6ca484b",
            "da51078f056b43adb3346cec49a0b684",
            "9156e9575bfe4997b26972cd63c57dcb",
            "f8dfb1f50d4c4bb3a5b454469ce52b06",
            "d68aabf41b3e4e698d58a51a525c615f",
            "24300f18381e4908b435b766e1429ba9",
            "6d67683590c6436585f9f085533f5f46",
            "30805b90dd034ee4a1207b7be08c065c",
            "00e25e1c02eb4f9ba5dc60f12cb88f6d",
            "3fb1ee36cac64f019fde5716c275a835",
            "c8e5d3cc1f6c476cb5d3f3cc4d4e2016",
            "e8c73dc6e687458ea97bfde2d0fbc62c",
            "64804237081d4087886a0be239260ce9",
            "bf19e51f0dc64463801c32e8933391d2",
            "a43fbe9147c84149abbab3fa11324aa0",
            "11a9ac056c524da59f3a0935c1fb036d",
            "874c6a9d15d74fff885c4bdfb6e2209f",
            "decc9c354bf24fdc8f265910d04490d9",
            "9e7182c32cd441078ef5a8330d66b37e",
            "30e2158e677d4153a4f642363c3daedb",
            "cc0d94b6f77c424c8be519b57213edc9",
            "a9d353e3f374425192a36013503db1a2",
            "9090df53e1b24cf3b6c696477d1b29ba"
          ]
        },
        "id": "EsmzWbGViYjI",
        "outputId": "229daa2d-a7b8-49b1-c564-0d42b7643aee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0714840aa8ea43009f9a6f25cf2b65cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da51078f056b43adb3346cec49a0b684"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64804237081d4087886a0be239260ce9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": ["tokenized_datasets"],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIXotI8wi4Qc",
        "outputId": "cb18d170-c8bf-4aa3-a429-10b8e833dd56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "tokenized_datasets[\"train\"].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uwi1gaTij6O",
        "outputId": "cbe4eab6-70f7-4276-c211-f1699b7714fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataloaders\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "pDerBcWQjBgz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we are padding to the maximum length inside the batch.\n",
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k:v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eGtu1TWjUEM",
        "outputId": "8e80d7f7-bf86-4aab-831d-7fd67c469a79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': torch.Size([8]),\n",
              " 'input_ids': torch.Size([8, 29]),\n",
              " 'token_type_ids': torch.Size([8, 29]),\n",
              " 'attention_mask': torch.Size([8, 29])}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "9070362e3d3c4e0b95d897cd6d2a0607",
            "8ecf50fa5ff84c5abbc9c3d1d6889eaf",
            "4a24d2176424427bbc240154aec904f1",
            "0616a8bb2b2f4781b2d3418aab2fd40f",
            "617367254889464391faf2d83a50f4bf",
            "7e28e5c8ac6e4c6c87154ab21d4d04c8",
            "1dde0567cd6d446ea4178f22b3df9c85",
            "99634d1b03954df88a745a0bf0a67b9b",
            "bff04661bcc84aafad88cedbc970f0d4",
            "0f412dfe81c54c86bdc75d7af6d1d87f",
            "c87d3da97a8641d7a4fb204bdd0d42da",
            "63177be381484afa97634592fab9e225",
            "348d2230072d484d81edff3c60d775f3",
            "8a6c4a46631940128973d3016b3b2fdb",
            "7298c448831646468c7d52c11218615b",
            "946182b2dfc84f44aeb196c9e7472e80",
            "da00932bfba146bfb1a7d4a9ea3908a9",
            "343412d88cf5411194e67fd7b6afbce6",
            "4b1cbfa4173248ffac0199cb87608947",
            "a8cf9aa52440434b85f1829b986f4b27",
            "5eae4a39e6694e2fb91ca0edfd217d10",
            "8a47c2f388f043a5b3cf19a279cb854b"
          ]
        },
        "collapsed": true,
        "id": "1LwruA9cj7bu",
        "outputId": "5b3c37fd-bb18-48e9-8d65-bfe33b162e5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9070362e3d3c4e0b95d897cd6d2a0607"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63177be381484afa97634592fab9e225"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "classifier.bias                            | MISSING    | \n",
            "classifier.weight                          | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": ["outputs = model(**batch)\n", "outputs.logits.shape"],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4qBIj2Ikual",
        "outputId": "af27a9b5-6c59-4f43-da02-0ab186b928f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ["torch.Size([8, 2])"]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need the optimizer and lr_Scheduler\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLwH6hJNlAfn",
        "outputId": "7c58c98a-e602-4bf1-9a9e-95452e94c016"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ["25257\n"]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# put model on gpu\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jAasZNHlWa2",
        "outputId": "d13a3c29-5332-431b-a6c4-ad694a50712e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ["device(type='cuda')"]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train on train_dataloader\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) #  gradient clipping\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "62a91db343834f6d8b1eb960a92a7252",
            "b272525ae6e14761bdb743803cf9d6da",
            "a3c3e7930c7e46c48442568ec91f7772",
            "3abc4e95402d439ca71331d411c1f269",
            "673121df12ec4c739a5c1ee959c7499e",
            "a2aa4338382c475c86839a95808f89dd",
            "e5f46af82fca44d8bdc7db601362fcde",
            "0cc5a76d823442a4bd10a0b1fe6cb211",
            "1a2ea8d10ddd44f6ae464acbc1b98fe0",
            "466aa475c3b54b838dcfe9588dd53b0d",
            "f3d98b5c2e0948e6be257d12dffbc272"
          ]
        },
        "id": "J05RTB3sl7qX",
        "outputId": "dd0f9bb7-ad5f-4e08-d17c-5a9071267678"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["  0%|          | 0/25257 [00:00<?, ?it/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62a91db343834f6d8b1eb960a92a7252"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1967127069.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interrupted because it will take around 30 mins to get trained."
      ],
      "metadata": {
        "id": "-x_Cis4rmcEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using accelerate\n",
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
        "\n",
        "accelerator = Accelerator()\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "\n",
        "train_dl, eval_dl, model, optimizer = accelerator.prepare(\n",
        "    train_dataloader, eval_dataloader, model, optimizer\n",
        ")\n",
        "\n",
        "num_epochs = 1 # lower for faster training\n",
        "num_training_steps = num_epochs * len(train_dl)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dl:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "506a89937a69445e8ed972835933a19d",
            "3c593fc2343c4ed3916d467b1dfdc8d8",
            "de4e8450110345a2a24fea4ed9b25a85",
            "595b0fddb8854ed49ef3fdd55308e5d4",
            "950b5939044e4d1db11d548f2ad57214",
            "2e628602d9734a38bde0cc8d8a44c00a",
            "f3655c7ec1d44e9992871cf0ba15ce57",
            "f1a1f0f8aedd46989ab40a460909fadd",
            "aa0eec0ba6e04f8db9d97be461332537",
            "608951a960064d7f80ece797f30db26c",
            "a432f307a2e74ebf9903a176f654a82d",
            "b42f40d0d925475a8a9caddf594e38ee",
            "78be2eba17564aec8d9bbb7765cd0ed6",
            "37540218fffd41d8bbc9881e61dbecb1",
            "9fe1eca22e764ff3ba1048ba7c9d271f",
            "c8b35e2f48cb422c9eeafa6f905903b9",
            "12d0c333f28845b886c10a2fe3bb70f9",
            "0b414cca7cd04bd28a3af5d5a7e36feb",
            "fb32476ddab745f1aabbc28d86c7622a",
            "df0fab2aba3145559a65e8604a1b0166",
            "90d8428f0adc49288179c0e20c5734e4",
            "0f6da43c41e04453bc6d4b0acb187fa0"
          ]
        },
        "id": "1kvAIBx6mS9h",
        "outputId": "8680e6c2-4c09-4cc8-80a7-acc405c2e771"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "506a89937a69445e8ed972835933a19d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "classifier.bias                            | MISSING    | \n",
            "classifier.weight                          | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["  0%|          | 0/8419 [00:00<?, ?it/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b42f40d0d925475a8a9caddf594e38ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  evaluate on evluation dataloader\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"sst2\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8e378e67949c4586a4fbbf898bfa26b4",
            "fd546b5ccedc445fbd36627dbd2bdc04",
            "6003b40f19e24f6c876bd7189bbc8181",
            "436e67c4b4db4ac4b1d8fbdc5f312cb7",
            "bef1a1166cfc416f9ee167b79cf9e993",
            "c958aa96fa6146c8a9a527a471fca473",
            "553c6ed343c94f349a837c5e371eb671",
            "77bc87ae66324cfaae14e91320f9af87",
            "f489eea72d7a49afa542bae7069761cb",
            "f5242d4e51e44b79bcb9fb3007e91132",
            "b68fa7aeb6184f63a2a51516b36e49b2"
          ]
        },
        "id": "L0Zt2jkPnW8X",
        "outputId": "3b424a80-2aef-4fa2-f271-ba3afe4a6299"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": ["Downloading builder script: 0.00B [00:00, ?B/s]"],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e378e67949c4586a4fbbf898bfa26b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": ["{'accuracy': 0.9334862385321101}"]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pq_MDY2npWoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
